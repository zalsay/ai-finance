
from req_res_types import *
import os
import sys
import pandas as pd
import numpy as np
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
pre_data_dir = os.path.join(parent_dir, 'preprocess_data')
sys.path.append(pre_data_dir)

from chunks_functions import create_chunks_from_test_data
from process_from_ak import df_preprocess
from math_functions import mean_squared_error, mean_absolute_error

def predict_single_chunk_mode1(
        chunk: pd.DataFrame, 
        tfm, 
        chunk_index: int
    ) -> ChunkPredictionResult:
    """
    æ¨¡å¼1ï¼šå¯¹å•ä¸ªåˆ†å—è¿›è¡Œé¢„æµ‹ï¼ˆå›ºå®šè®­ç»ƒé›†ï¼Œä½¿ç”¨ak_stock_dataç”Ÿæˆæµ‹è¯•æ•°æ®ï¼‰
    
    Args:
        df_train: å›ºå®šçš„è®­ç»ƒæ•°æ®
        chunk: å½“å‰åˆ†å—çš„æµ‹è¯•æ•°æ®
        tfm: TimesFMæ¨¡å‹å®ä¾‹
        stock_code: è‚¡ç¥¨ä»£ç 
        chunk_index: åˆ†å—ç´¢å¼•
        
    Returns:
        ChunkPredictionResult: åˆ†å—é¢„æµ‹ç»“æœ
    """
    try:
        # ä½¿ç”¨æ–°æ•°æ®é›†è¿›è¡Œé¢„æµ‹
        forecast_df = tfm.forecast_on_df(
            inputs=chunk,
            freq="D",
            value_name="close",
            num_jobs=1,
        )
        
        # è·å–é¢„æµ‹ç»“æœçš„å‰horizon_lenæ¡è®°å½•
        horizon_len = len(chunk)
        forecast_chunk = forecast_df.head(horizon_len)
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°é¢„æµ‹ç»“æœçš„åˆ—å
        print(f"  é¢„æµ‹ç»“æœåˆ—å: {list(forecast_df.columns)}")
        print(f"  é¢„æµ‹ç»“æœå½¢çŠ¶: {forecast_df.shape}")
        
        # æå–é¢„æµ‹å€¼å’Œå®é™…å€¼
        actual_values = chunk['close'].tolist()
        
        # è·å–æ‰€æœ‰é¢„æµ‹åˆ†ä½æ•°
        predictions = {}
        forecast_columns = [col for col in forecast_chunk.columns if col.startswith('timesfm-q-')]
        
        print(f"  æ‰¾åˆ°çš„é¢„æµ‹åˆ—: {forecast_columns}")
        
        for col in forecast_columns:
            predictions[col] = forecast_chunk[col].tolist()
        
        # è®¡ç®—æ‰€æœ‰åˆ†ä½æ•°çš„è¯„ä¼°æŒ‡æ ‡
        quantile_metrics = {}
        best_quantile = None
        best_score = float('inf')
        
        # å®šä¹‰è¦è¯„ä¼°çš„åˆ†ä½æ•°èŒƒå›´ (0.1 åˆ° 0.9)
        target_quantiles = [f'timesfm-q-0.{i}' for i in range(1, 10)]
        
        for quantile in target_quantiles:
            if quantile in predictions:
                pred_values = predictions[quantile]
                
                # ç¡®ä¿é¢„æµ‹å€¼å’Œå®é™…å€¼é•¿åº¦ä¸€è‡´
                min_len = min(len(pred_values), len(actual_values))
                pred_values_trimmed = pred_values[:min_len]
                actual_values_trimmed = actual_values[:min_len]
                
                # è®¡ç®—MSEå’ŒMAE
                mse_q = mean_squared_error(np.array(pred_values_trimmed), np.array(actual_values_trimmed))
                mae_q = mean_absolute_error(np.array(pred_values_trimmed), np.array(actual_values_trimmed))
                
                # è®¡ç®—ç»¼åˆå¾—åˆ† (MSEå’ŒMAEå„å 50%æƒé‡)
                # ä¸ºäº†ç»Ÿä¸€é‡çº²ï¼Œå¯¹MSEå’ŒMAEè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
                combined_score = 0.5 * mse_q + 0.5 * mae_q
                
                quantile_metrics[quantile] = {
                    'mse': mse_q,
                    'mae': mae_q,
                    'combined_score': combined_score
                }
                
                # æ‰¾åˆ°æœ€ä¼˜åˆ†ä½æ•°
                if combined_score < best_score:
                    best_score = combined_score
                    best_quantile = quantile
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„åˆ†ä½æ•°é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not quantile_metrics:
            print(f"  âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ä½æ•°é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            mse = 0.0
            mae = 0.0
            best_quantile = 'timesfm-q-0.5'
        else:
            # ä½¿ç”¨æœ€ä¼˜åˆ†ä½æ•°çš„æŒ‡æ ‡
            mse = quantile_metrics[best_quantile]['mse']
            mae = quantile_metrics[best_quantile]['mae']
            
            print(f"  ğŸ“Š åˆ†ä½æ•°è¯„ä¼°ç»“æœ:")
            for q, metrics in quantile_metrics.items():
                print(f"    {q}: MSE={metrics['mse']:.6f}, MAE={metrics['mae']:.6f}, ç»¼åˆå¾—åˆ†={metrics['combined_score']:.6f}")
            print(f"  ğŸ† æœ€ä¼˜åˆ†ä½æ•°: {best_quantile} (ç»¼åˆå¾—åˆ†: {best_score:.6f})")
        
        # è·å–åˆ†å—çš„æ—¥æœŸèŒƒå›´
        chunk_start_date = chunk['ds'].min().strftime('%Y-%m-%d')
        chunk_end_date = chunk['ds'].max().strftime('%Y-%m-%d')
        
        return ChunkPredictionResult(
            chunk_index=chunk_index,
            chunk_start_date=chunk_start_date,
            chunk_end_date=chunk_end_date,
            predictions=predictions,
            actual_values=actual_values,
            metrics={
                'mse': mse, 
                'mae': mae,
                'best_quantile': best_quantile,
                'best_combined_score': best_score,
                'all_quantile_metrics': quantile_metrics
            }
        )
        
    except Exception as e:
        print(f"åˆ†å— {chunk_index} é¢„æµ‹å¤±è´¥: {str(e)}")
        # è¿”å›ç©ºç»“æœ
        return ChunkPredictionResult(
            chunk_index=chunk_index,
            chunk_start_date="",
            chunk_end_date="",
            predictions={},
            actual_values=[],
            metrics={
                'mse': float('inf'), 
                'mae': float('inf'),
                'best_quantile': 'timesfm-q-0.5',
                'best_combined_score': float('inf'),
                'all_quantile_metrics': {}
            }
        )

def predict_chunked_mode1(request: ChunkedPredictionRequest, tfm) -> ChunkedPredictionResponse:
    """
    æ¨¡å¼1åˆ†å—é¢„æµ‹ä¸»å‡½æ•°
    
    Args:
        request: åˆ†å—é¢„æµ‹è¯·æ±‚
        tfm: TimesFMæ¨¡å‹å®ä¾‹
        
    Returns:
        ChunkedPredictionResponse: åˆ†å—é¢„æµ‹å“åº”
    """
    import time
    start_time = time.time()
    
    try:
        # æ•°æ®é¢„å¤„ç†
        df_original, df_train, df_test = df_preprocess(
            request.stock_code, 
            request.stock_type, 
            request.time_step, 
            years=request.years, 
            horizon_len=request.horizon_len
        )
        
        # æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æˆåŠŸ
        if df_original is None or df_train is None or df_test is None:
            print(f"âŒ è‚¡ç¥¨ {request.stock_code} æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            # è¿”å›ä¸€ä¸ªç©ºçš„å“åº”å¯¹è±¡
            return ChunkedPredictionResponse(
                stock_code=request.stock_code,
                total_chunks=0,
                horizon_len=request.horizon_len,
                chunk_results=[],
                overall_metrics={
                    'avg_mse': float('inf'),
                    'avg_mae': float('inf'),
                    'error': 'Data preprocessing failed'
                },
                processing_time=time.time() - start_time
            )
        
        # æ·»åŠ å”¯ä¸€æ ‡è¯†ç¬¦
        df_train["unique_id"] = df_train["stock_code"].astype(str)
        df_test["unique_id"] = df_test["stock_code"].astype(str)
        
        # å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†å—
        chunks = create_chunks_from_test_data(df_test, request.horizon_len)
        
        # å¯¹æ¯ä¸ªåˆ†å—è¿›è¡Œé¢„æµ‹
        chunk_results = []
        all_mse = []
        all_mae = []
        
        for i, chunk in enumerate(chunks):
            print(f"æ­£åœ¨å¤„ç†åˆ†å— {i+1}/{len(chunks)}...")
            
            result = predict_single_chunk_mode1(
                chunk=chunk,
                tfm=tfm,
                chunk_index=i
            )
            
            chunk_results.append(result)
            
            # æ”¶é›†æŒ‡æ ‡ç”¨äºè®¡ç®—æ€»ä½“æŒ‡æ ‡
            if result.metrics['mse'] != float('inf'):
                all_mse.append(result.metrics['mse'])
                all_mae.append(result.metrics['mae'])
        
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        overall_metrics = {
            'avg_mse': np.mean(all_mse) if all_mse else float('inf'),
            'avg_mae': np.mean(all_mae) if all_mae else float('inf'),
            'total_chunks': len(chunks),
            'successful_chunks': len(all_mse)
        }
        
        # æ‹¼æ¥æ‰€æœ‰åˆ†å—çš„é¢„æµ‹ç»“æœ
        concatenated_predictions = {}
        concatenated_actual = []
        concatenated_dates = []
        
        if chunk_results:
            # è·å–é¢„æµ‹åˆ—åï¼ˆä»ç¬¬ä¸€ä¸ªåˆ†å—ç»“æœä¸­è·å–ï¼‰
            prediction_columns = list(chunk_results[0].predictions.keys())
            
            # åˆå§‹åŒ–æ‹¼æ¥é¢„æµ‹ç»“æœå­—å…¸
            for col in prediction_columns:
                concatenated_predictions[col] = []
            
            # æ‹¼æ¥æ¯ä¸ªåˆ†å—çš„ç»“æœ
            for result in chunk_results:
                # æ‹¼æ¥é¢„æµ‹å€¼
                for col in prediction_columns:
                    concatenated_predictions[col].extend(result.predictions[col])
                
                # æ‹¼æ¥å®é™…å€¼
                concatenated_actual.extend(result.actual_values)
                
                # ç”Ÿæˆæ—¥æœŸåºåˆ—ï¼ˆåŸºäºåˆ†å—çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼‰
                start_date = pd.to_datetime(result.chunk_start_date)
                end_date = pd.to_datetime(result.chunk_end_date)
                chunk_dates = pd.date_range(start=start_date, end=end_date, freq='D')
                concatenated_dates.extend([date.strftime('%Y-%m-%d') for date in chunk_dates[:len(result.actual_values)]])
        
        processing_time = time.time() - start_time
        
        return ChunkedPredictionResponse(
            stock_code=request.stock_code,
            total_chunks=len(chunks),
            horizon_len=request.horizon_len,
            chunk_results=chunk_results,
            overall_metrics=overall_metrics,
            processing_time=processing_time,
            concatenated_predictions=concatenated_predictions if concatenated_predictions else None,
            concatenated_actual=concatenated_actual if concatenated_actual else None,
            concatenated_dates=concatenated_dates if concatenated_dates else None
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"åˆ†å—é¢„æµ‹å¤±è´¥: {str(e)}")
        
        return ChunkedPredictionResponse(
            stock_code=request.stock_code,
            total_chunks=0,
            horizon_len=request.horizon_len,
            chunk_results=[],
            overall_metrics={'avg_mse': float('inf'), 'avg_mae': float('inf'), 'error': str(e)},
            processing_time=processing_time
        )