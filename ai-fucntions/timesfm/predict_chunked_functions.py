
from req_res_types import *
import os
import sys
import pandas as pd
import numpy as np
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
finance_dir = parent_dir
pre_data_dir = os.path.join(parent_dir, 'preprocess_data')
sys.path.append(pre_data_dir)

from chunks_functions import create_chunks_from_test_data
from process_from_ak import df_preprocess
from math_functions import mean_squared_error, mean_absolute_error

def predict_single_chunk_mode1(
        df_train: pd.DataFrame,
        chunk: pd.DataFrame, 
        tfm, 
        stock_code: str,
        chunk_index: int
    ) -> ChunkPredictionResult:
    """
    æ¨¡å¼1ï¼šå¯¹å•ä¸ªåˆ†å—è¿›è¡Œé¢„æµ‹ï¼ˆå›ºå®šè®­ç»ƒé›†ï¼Œä½¿ç”¨ak_stock_dataç”Ÿæˆæµ‹è¯•æ•°æ®ï¼‰
    
    Args:
        df_train: å›ºå®šçš„è®­ç»ƒæ•°æ®
        chunk: å½“å‰åˆ†å—çš„æµ‹è¯•æ•°æ®
        tfm: TimesFMæ¨¡å‹å®ä¾‹
        stock_code: è‚¡ç¥¨ä»£ç 
        chunk_index: åˆ†å—ç´¢å¼•
        
    Returns:
        ChunkPredictionResult: åˆ†å—é¢„æµ‹ç»“æœ
    """
    try:
        # ä½¿ç”¨æ–°æ•°æ®é›†è¿›è¡Œé¢„æµ‹
        forecast_df = tfm.forecast_on_df(
            inputs=df_train,
            freq="D",
            value_name="close",
            num_jobs=1,
        )
        
        # è·å–é¢„æµ‹ç»“æœçš„å‰horizon_lenæ¡è®°å½•
        horizon_len = len(chunk)
        forecast_chunk = forecast_df.head(horizon_len)
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°é¢„æµ‹ç»“æœçš„åˆ—å
        print(f"  é¢„æµ‹ç»“æœåˆ—å: {list(forecast_df.columns)}")
        print(f"  é¢„æµ‹ç»“æœå½¢çŠ¶: {forecast_df.shape}")
        
        # æå–é¢„æµ‹å€¼å’Œå®é™…å€¼
        actual_values = chunk['close'].tolist()
        
        # è·å–æ‰€æœ‰é¢„æµ‹åˆ†ä½æ•°
        predictions = {}
        forecast_columns = [col for col in forecast_chunk.columns if col.startswith('timesfm-q-')]
        
        print(f"  æ‰¾åˆ°çš„é¢„æµ‹åˆ—: {forecast_columns}")
        
        for col in forecast_columns:
            predictions[col] = forecast_chunk[col].tolist()
        
        # è®¡ç®—æ‰€æœ‰åˆ†ä½æ•°çš„è¯„ä¼°æŒ‡æ ‡
        quantile_metrics = {}
        best_quantile = None
        best_score = float('inf')
        
        # å®šä¹‰è¦è¯„ä¼°çš„åˆ†ä½æ•°èŒƒå›´ (0.1 åˆ° 0.9)
        target_quantiles = [f'timesfm-q-0.{i}' for i in range(1, 10)]
        
        for quantile in target_quantiles:
            if quantile in predictions:
                pred_values = predictions[quantile]
                
                # ç¡®ä¿é¢„æµ‹å€¼å’Œå®é™…å€¼é•¿åº¦ä¸€è‡´
                min_len = min(len(pred_values), len(actual_values))
                pred_values_trimmed = pred_values[:min_len]
                actual_values_trimmed = actual_values[:min_len]
                
                # è®¡ç®—MSEå’ŒMAE
                mse_q = mean_squared_error(np.array(pred_values_trimmed), np.array(actual_values_trimmed))
                mae_q = mean_absolute_error(np.array(pred_values_trimmed), np.array(actual_values_trimmed))
                
                # è®¡ç®—ç»¼åˆå¾—åˆ† (MSEå’ŒMAEå„å 50%æƒé‡)
                # ä¸ºäº†ç»Ÿä¸€é‡çº²ï¼Œå¯¹MSEå’ŒMAEè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
                combined_score = 0.5 * mse_q + 0.5 * mae_q
                
                quantile_metrics[quantile] = {
                    'mse': mse_q,
                    'mae': mae_q,
                    'combined_score': combined_score
                }
                
                # æ‰¾åˆ°æœ€ä¼˜åˆ†ä½æ•°
                if combined_score < best_score:
                    best_score = combined_score
                    best_quantile = quantile
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„åˆ†ä½æ•°é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not quantile_metrics:
            print(f"  âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ä½æ•°é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            mse = 0.0
            mae = 0.0
            best_quantile = 'timesfm-q-0.5'
        else:
            # ä½¿ç”¨æœ€ä¼˜åˆ†ä½æ•°çš„æŒ‡æ ‡
            mse = quantile_metrics[best_quantile]['mse']
            mae = quantile_metrics[best_quantile]['mae']
            
            print(f"  ğŸ“Š åˆ†ä½æ•°è¯„ä¼°ç»“æœ:")
            for q, metrics in quantile_metrics.items():
                print(f"    {q}: MSE={metrics['mse']:.6f}, MAE={metrics['mae']:.6f}, ç»¼åˆå¾—åˆ†={metrics['combined_score']:.6f}")
            print(f"  ğŸ† æœ€ä¼˜åˆ†ä½æ•°: {best_quantile} (ç»¼åˆå¾—åˆ†: {best_score:.6f})")
        
        # è·å–å®é™…å€¼å’Œé¢„æµ‹å€¼å¯¹åº”çš„æ—¥æœŸèŒƒå›´
        # å®é™…å€¼å’Œé¢„æµ‹å€¼å¯¹åº”çš„æ˜¯åˆ†å—ä¸­çš„æœ€åhorizon_lenä¸ªæ—¥æœŸ
        chunk_dates = chunk['ds'].tolist()
        prediction_start_date = chunk_dates[-len(actual_values)].strftime('%Y-%m-%d') if len(actual_values) > 0 else chunk['ds'].min().strftime('%Y-%m-%d')
        prediction_end_date = chunk_dates[-1].strftime('%Y-%m-%d')
        
        # ä¿æŒåŸæœ‰çš„åˆ†å—æ—¥æœŸèŒƒå›´ä½œä¸ºå¤‡ç”¨
        chunk_start_date = prediction_start_date
        chunk_end_date = prediction_end_date
        
        return ChunkPredictionResult(
            chunk_index=chunk_index,
            chunk_start_date=chunk_start_date,
            chunk_end_date=chunk_end_date,
            predictions=predictions,
            actual_values=actual_values,
            metrics={
                'mse': mse, 
                'mae': mae,
                'best_quantile': best_quantile,
                'best_combined_score': best_score,
                'all_quantile_metrics': quantile_metrics
            }
        )
        
    except Exception as e:
        print(f"åˆ†å— {chunk_index} é¢„æµ‹å¤±è´¥: {str(e)}")
        # è¿”å›ç©ºç»“æœ
        return ChunkPredictionResult(
            chunk_index=chunk_index,
            chunk_start_date="",
            chunk_end_date="",
            predictions={},
            actual_values=[],
            metrics={
                'mse': float('inf'), 
                'mae': float('inf'),
                'best_quantile': 'timesfm-q-0.5',
                'best_combined_score': float('inf'),
                'all_quantile_metrics': {}
            }
        )

def predict_chunked_mode1(request: ChunkedPredictionRequest, tfm) -> ChunkedPredictionResponse:
    """
    æ¨¡å¼1åˆ†å—é¢„æµ‹ä¸»å‡½æ•°
    
    Args:
        request: åˆ†å—é¢„æµ‹è¯·æ±‚
        tfm: TimesFMæ¨¡å‹å®ä¾‹
        
    Returns:
        ChunkedPredictionResponse: åˆ†å—é¢„æµ‹å“åº”
    """
    import time
    start_time = time.time()
    
    try:
        # æ•°æ®é¢„å¤„ç†
        df_original, df_train, df_test = df_preprocess(
            request.stock_code, 
            request.stock_type, 
            request.start_date,
            request.end_date,
            request.time_step, 
            years=request.years, 
            horizon_len=request.horizon_len
        )
        
        # æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æˆåŠŸ
        if df_original is None or df_train is None or df_test is None:
            print(f"âŒ è‚¡ç¥¨ {request.stock_code} æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            # è¿”å›ä¸€ä¸ªç©ºçš„å“åº”å¯¹è±¡
            return ChunkedPredictionResponse(
                stock_code=request.stock_code,
                total_chunks=0,
                horizon_len=request.horizon_len,
                chunk_results=[],
                overall_metrics={
                    'avg_mse': float('inf'),
                    'avg_mae': float('inf'),
                    'error': 'Data preprocessing failed'
                },
                processing_time=time.time() - start_time
            )
        print(f"âœ… è‚¡ç¥¨ {request.stock_code} æ•°æ®é¢„å¤„ç†æˆåŠŸï¼Œtestå¼€å§‹æ—¥æœŸ: {df_test['ds'].min().strftime('%Y-%m-%d')}")
        # æ·»åŠ å”¯ä¸€æ ‡è¯†ç¬¦
        df_train["unique_id"] = df_train["stock_code"].astype(str)
        df_test["unique_id"] = df_test["stock_code"].astype(str)
        
        # å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†å—
        chunks = create_chunks_from_test_data(df_test, request.horizon_len)
        active_chunks = chunks[:request.chunk_num]
        # å¯¹æ¯ä¸ªåˆ†å—è¿›è¡Œé¢„æµ‹
        chunk_results = []
        all_mse = []
        all_mae = []
        
        for i, chunk in enumerate(active_chunks):
            print(f"æ­£åœ¨å¤„ç†åˆ†å— {i+1}/{len(active_chunks)}...")
            
            result = predict_single_chunk_mode1(
                chunk=chunk,
                tfm=tfm,
                chunk_index=i
            )
            
            chunk_results.append(result)
            
            # æ”¶é›†æŒ‡æ ‡ç”¨äºè®¡ç®—æ€»ä½“æŒ‡æ ‡
            if result.metrics['mse'] != float('inf'):
                all_mse.append(result.metrics['mse'])
                all_mae.append(result.metrics['mae'])
        
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        overall_metrics = {
            'avg_mse': np.mean(all_mse) if all_mse else float('inf'),
            'avg_mae': np.mean(all_mae) if all_mae else float('inf'),
            'total_chunks': len(chunks),
            'successful_chunks': len(all_mse)
        }
        
        # æ‹¼æ¥æ‰€æœ‰åˆ†å—çš„é¢„æµ‹ç»“æœ
        concatenated_predictions = {}
        concatenated_actual = []
        concatenated_dates = []
        
        if chunk_results:
            # è·å–é¢„æµ‹åˆ—åï¼ˆä»ç¬¬ä¸€ä¸ªåˆ†å—ç»“æœä¸­è·å–ï¼‰
            prediction_columns = list(chunk_results[0].predictions.keys())
            
            # åˆå§‹åŒ–æ‹¼æ¥é¢„æµ‹ç»“æœå­—å…¸
            for col in prediction_columns:
                concatenated_predictions[col] = []
            
            # æ‹¼æ¥æ¯ä¸ªåˆ†å—çš„ç»“æœ
            for result in chunk_results:
                # æ‹¼æ¥é¢„æµ‹å€¼
                for col in prediction_columns:
                    concatenated_predictions[col].extend(result.predictions[col])
                
                # æ‹¼æ¥å®é™…å€¼
                concatenated_actual.extend(result.actual_values)
                
                # ç”Ÿæˆæ—¥æœŸåºåˆ—ï¼ˆåŸºäºåˆ†å—çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼‰
                start_date = pd.to_datetime(result.chunk_start_date)
                end_date = pd.to_datetime(result.chunk_end_date)
                chunk_dates = pd.date_range(start=start_date, end=end_date, freq='D')
                concatenated_dates.extend([date.strftime('%Y-%m-%d') for date in chunk_dates[:len(result.actual_values)]])
        
        processing_time = time.time() - start_time
        
        return ChunkedPredictionResponse(
            stock_code=request.stock_code,
            total_chunks=len(chunks),
            horizon_len=request.horizon_len,
            chunk_results=chunk_results,
            overall_metrics=overall_metrics,
            processing_time=processing_time,
            concatenated_predictions=concatenated_predictions if concatenated_predictions else None,
            concatenated_actual=concatenated_actual if concatenated_actual else None,
            concatenated_dates=concatenated_dates if concatenated_dates else None
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"åˆ†å—é¢„æµ‹å¤±è´¥: {str(e)}")
        
        return ChunkedPredictionResponse(
            stock_code=request.stock_code,
            total_chunks=0,
            horizon_len=request.horizon_len,
            chunk_results=[],
            overall_metrics={'avg_mse': float('inf'), 'avg_mae': float('inf'), 'error': str(e)},
            processing_time=processing_time
        )

if __name__ == "__main__":
    from timesfm_init import init_timesfm
    test_request = ChunkedPredictionRequest(
        stock_code="000002",
        years=10,
        horizon_len=7,
        start_date="2023-06-30",
        end_date="2025-08-30",
        context_len=2048,
        time_step=0,
        stock_type='stock',
        chunk_num=1
    )
    tfm = init_timesfm(horizon_len=test_request.horizon_len, context_len=test_request.context_len)
    response = predict_chunked_mode1(test_request, tfm)
    # print(response)
    # è¾“å‡ºç»“æœ
    print(f"\n=== åˆ†å—é¢„æµ‹ç»“æœ ===")
    print(f"è‚¡ç¥¨ä»£ç : {response.stock_code}")
    print(f"æ€»åˆ†å—æ•°: {response.total_chunks}")
    print(f"é¢„æµ‹é•¿åº¦: {response.horizon_len}")
    print(f"å¤„ç†æ—¶é—´: {response.processing_time:.2f} ç§’")
    
    # print(f"\n=== æ€»ä½“æŒ‡æ ‡ ===")
    # for metric, value in response.overall_metrics.items():
    #     if isinstance(value, float) and value != float('inf'):
    #         print(f"{metric}: {value:.6f}")
    #     else:
    #         print(f"{metric}: {value}")
    
    print(f"\n=== å„åˆ†å—è¯¦ç»†ç»“æœ ===")
    for i, chunk_result in enumerate(response.chunk_results):
        print(f"\nåˆ†å— {i+1}:")
        print(f"  ç´¢å¼•: {chunk_result.chunk_index}")
        print(f"  é¢„æµ‹æ—¥æœŸèŒƒå›´: {chunk_result.chunk_start_date} åˆ° {chunk_result.chunk_end_date}")
        print(f"  å®é™…å€¼æ—¥æœŸèŒƒå›´: {chunk_result.chunk_start_date} åˆ° {chunk_result.chunk_end_date}")
        print(f"  å®é™…å€¼æ•°é‡: {len(chunk_result.actual_values)}")
        print(f"  é¢„æµ‹åˆ—æ•°é‡: {len(chunk_result.predictions)}")
        
        # æ˜¾ç¤ºæŒ‡æ ‡
        # for metric, value in chunk_result.metrics.items():
        #     if isinstance(value, float) and value != float('inf'):
        #         print(f"  {metric}: {value:.6f}")
        #     else:
        #         print(f"  {metric}: {value}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªé¢„æµ‹å€¼å’Œå®é™…å€¼
        if chunk_result.actual_values and chunk_result.predictions:
            print(f"  å‰3ä¸ªå®é™…å€¼: {chunk_result.actual_values[:3]}")
            
            # æ˜¾ç¤ºä¸­ä½æ•°é¢„æµ‹å€¼
            if 'timesfm-q-0.5' in chunk_result.predictions:
                pred_values = chunk_result.predictions['timesfm-q-0.5']
                print(f"  å‰3ä¸ªé¢„æµ‹å€¼: {pred_values[:3]}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    mode_suffix = "chunked"
    results_filename = os.path.join(finance_dir, f"forecast-results/{test_request.stock_code}_{mode_suffix}_prediction_results.txt")
    with open(results_filename, 'w', encoding='utf-8') as f:
        f.write(f"ç»“æœ - è‚¡ç¥¨: {response.stock_code}\n")
        f.write(f"æ€»åˆ†å—æ•°: {response.total_chunks}\n")
        f.write(f"é¢„æµ‹é•¿åº¦: {response.horizon_len}\n")
        f.write(f"å¤„ç†æ—¶é—´: {response.processing_time:.2f} ç§’\n\n")
        
        f.write("æ€»ä½“æŒ‡æ ‡:\n")
        for metric, value in response.overall_metrics.items():
            f.write(f"  {metric}: {value}\n")
        
        f.write("\nå„åˆ†å—è¯¦ç»†ç»“æœ:\n")
        for chunk_result in response.chunk_results:
            f.write(f"\nåˆ†å— {chunk_result.chunk_index + 1}:\n")
            f.write(f"  é¢„æµ‹æ—¥æœŸèŒƒå›´: {chunk_result.chunk_start_date} åˆ° {chunk_result.chunk_end_date}\n")
            f.write(f"  å®é™…å€¼æ—¥æœŸèŒƒå›´: {chunk_result.chunk_start_date} åˆ° {chunk_result.chunk_end_date}\n")
            f.write(f"  æŒ‡æ ‡: {chunk_result.metrics}\n")
            f.write(f"  å®é™…å€¼: {chunk_result.actual_values}\n")
            f.write(f"  é¢„æµ‹å€¼: {chunk_result.predictions}\n")
    
    # ç”Ÿæˆç»˜å›¾
    from plot_functions import plot_chunked_prediction_results
    print(f"\næ­£åœ¨ç”Ÿæˆç»“æœå›¾è¡¨...")
    plot_save_path = os.path.join(finance_dir, f"forecast-results/{test_request.stock_code}_{mode_suffix}_prediction_plot.png")
    try:
        plot_path = plot_chunked_prediction_results(response, plot_save_path)
        print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_path}")
    except Exception as plot_error:
        print(f"âš ï¸ ç»˜å›¾å¤±è´¥: {str(plot_error)}")
    
    print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_filename}")
    
