
from req_res_types import *
import os
import sys
import pandas as pd
import numpy as np
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
finance_dir = parent_dir
pre_data_dir = os.path.join(parent_dir, 'preprocess_data')
sys.path.append(pre_data_dir)

# å¯¼å…¥å…¶ä»–æ¨¡å—
from chunks_functions import create_chunks_from_test_data
from processor import df_preprocess
from math_functions import mean_squared_error, mean_absolute_error

# åœ¨éœ€è¦æ—¶æ‰å¯¼å…¥timesfm-2.5ç‰ˆæœ¬çš„inferenceæ¨¡å—
def import_predict_2p5():
    # ä¿å­˜åŸå§‹sys.path
    original_sys_path = sys.path.copy()
    
    # æ·»åŠ timesfm-2p5-functionsè·¯å¾„å’Œtimesfm-2.5æºç è·¯å¾„
    timesfm_2P5_dir = os.path.join(current_dir, "timesfm-2p5-functions")
    timesfm_src = os.path.join(timesfm_2P5_dir, "timesfm-2.5", "src")
    
    # åªæ·»åŠ å¿…è¦çš„è·¯å¾„ï¼Œè€Œä¸æ˜¯å®Œå…¨æ›¿æ¢sys.path
    sys.path.insert(0, timesfm_src)
    sys.path.insert(0, timesfm_2P5_dir)
    
    try:
        from inference import predict_2p5
        return predict_2p5
    finally:
        # æ¢å¤åŸå§‹sys.path
        sys.path = original_sys_path

def predict_single_chunk_mode1(
        df_train: pd.DataFrame,
        df_test: pd.DataFrame, 
        tfm, 
        chunk_index: int,
        timesfm_version: str = "2.0",
        symbol: str = ""
    ) -> ChunkPredictionResult:
    """
    æ¨¡å¼1ï¼šå¯¹å•ä¸ªåˆ†å—è¿›è¡Œé¢„æµ‹ï¼ˆå›ºå®šè®­ç»ƒé›†ï¼Œä½¿ç”¨ak_stock_dataç”Ÿæˆæµ‹è¯•æ•°æ®ï¼‰
    
    Args:
        df_train: å›ºå®šçš„è®­ç»ƒæ•°æ®
        df_test: å½“å‰åˆ†å—çš„æµ‹è¯•æ•°æ®
        tfm: TimesFMæ¨¡å‹å®ä¾‹
        stock_code: è‚¡ç¥¨ä»£ç 
        chunk_index: åˆ†å—ç´¢å¼•
        
    Returns:
        ChunkPredictionResult: åˆ†å—é¢„æµ‹ç»“æœ
    """
    try:
        if timesfm_version == "2.0":
            # ä½¿ç”¨æ–°æ•°æ®é›†è¿›è¡Œé¢„æµ‹
            print(f"æ­£åœ¨ä½¿ç”¨TimesFM-2.0æ¨¡å‹å¯¹æµ‹è¯•é›†åˆ†å— {chunk_index} è¿›è¡Œé¢„æµ‹...")
            forecast_df = tfm.forecast_on_df(
                inputs=df_train,
                freq="D",
                value_name="close",
                num_jobs=1,
            )
            rename_dict = {c: f"tsf-{c.split('timesfm-q-')[1]}" for c in forecast_df.columns if c.startswith('timesfm-q-')}
            rename_dict["timesfm"] = "tsf"
            if rename_dict:
                forecast_df = forecast_df.rename(columns=rename_dict)
        elif timesfm_version == "2.5":
            print(f"æ­£åœ¨ä½¿ç”¨TimesFM-2.5æ¨¡å‹å¯¹æµ‹è¯•é›†åˆ†å— {chunk_index} è¿›è¡Œé¢„æµ‹...")
            predict_2p5_func = import_predict_2p5()
            forecast_df = predict_2p5_func(df_train, pred_horizon=len(df_test), unique_id=symbol)

        
        # è·å–é¢„æµ‹ç»“æœçš„å‰horizon_lenæ¡è®°å½•
        horizon_len = len(df_test)
        forecast_chunk = forecast_df.head(horizon_len)
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°é¢„æµ‹ç»“æœçš„åˆ—å
        # print(f"  é¢„æµ‹ç»“æœåˆ—å: {list(forecast_df.columns)}")
        # print(f"  é¢„æµ‹ç»“æœå½¢çŠ¶: {forecast_df.shape}")
        # print(f"  é¢„æµ‹ç»“æœå‰{horizon_len}è¡Œ: ")
        # print(forecast_chunk.head(horizon_len))
        # print(f"  æµ‹è¯•æ•°æ®å‰{horizon_len}è¡Œ: ")
        # print(df_test.head(horizon_len))

        # æå–é¢„æµ‹å€¼å’Œå®é™…å€¼
        actual_values = df_test['close'].tolist()
        actual_dates = df_test['ds'].tolist()
        # print(f"  å®é™…æ—¥æœŸå‰7è¡Œ: {actual_dates[:7]}")
        # è·å–æ‰€æœ‰é¢„æµ‹åˆ†ä½æ•°
        predictions = {}
        forecast_columns = [col for col in forecast_chunk.columns if col.startswith('tsf-')]
        
        # print(f"æ‰¾åˆ°çš„é¢„æµ‹åˆ—: {forecast_columns}")
        
        for col in forecast_columns:
            predictions[col] = forecast_chunk[col].tolist()
        
        # è®¡ç®—æ‰€æœ‰åˆ†ä½æ•°çš„è¯„ä¼°æŒ‡æ ‡
        quantile_metrics = {}
        best_quantile_colname = None
        best_quantile_colname_pct = None
        best_score = float('inf')
        best_diff_pct = float('inf') # æœ€ä¼˜æ¶¨è·Œå¹…ç™¾åˆ†æ¯”å·®
        # å®šä¹‰è¦è¯„ä¼°çš„åˆ†ä½æ•°èŒƒå›´ (0.1 åˆ° 0.9)
        target_quantiles = [f'tsf-0.{i}' for i in range(1, 10)]
        
        for quantile in target_quantiles:
            if quantile in predictions:
                pred_values = predictions[quantile]
                
                # ç¡®ä¿é¢„æµ‹å€¼å’Œå®é™…å€¼é•¿åº¦ä¸€è‡´
                min_len = min(len(pred_values), len(actual_values))
                pred_values_trimmed = pred_values[:min_len]
                actual_values_trimmed = actual_values[:min_len]
                
                # è®¡ç®—MSEå’ŒMAE
                mse_q = mean_squared_error(np.array(pred_values_trimmed), np.array(actual_values_trimmed))
                mae_q = mean_absolute_error(np.array(pred_values_trimmed), np.array(actual_values_trimmed))
                pct_q = (pred_values_trimmed[-1] / actual_values_trimmed[0] - 1) * 100
                actual_pct = (actual_values_trimmed[-1] / actual_values_trimmed[0] - 1) * 100
                diff_pct = abs(pct_q - actual_pct) / actual_pct # é¢„æµ‹æ¶¨è·Œå¹…ä¸å®é™…æ¶¨è·Œå¹…çš„ç™¾åˆ†æ¯”å·®
                # è®¡ç®—ç»¼åˆå¾—åˆ† (MSEå’ŒMAEå„å 50%æƒé‡)
                # ä¸ºäº†ç»Ÿä¸€é‡çº²ï¼Œå¯¹MSEå’ŒMAEè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
                combined_score = 0.5 * mse_q + 0.5 * mae_q
                
                quantile_metrics[quantile] = {
                    'mse': mse_q,
                    'mae': mae_q,
                    'combined_score': combined_score,
                    'pred_pct': pct_q,
                    'actual_pct': actual_pct,
                    'diff_pct': diff_pct,
                    'pred_values': pred_values_trimmed,
                    'actual_values': actual_values_trimmed
                }
                
                # æ‰¾åˆ°æœ€ä¼˜åˆ†ä½æ•°
                if combined_score < best_score:
                    best_score = combined_score
                    best_quantile_colname = quantile
                if diff_pct < best_diff_pct:
                    best_diff_pct = diff_pct
                    best_quantile_colname_pct = quantile
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„åˆ†ä½æ•°é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not quantile_metrics:
            print(f"  âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ä½æ•°é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            mse = 0.0
            mae = 0.0
            best_quantile_colname = 'tsf-0.5'
        else:
            # ä½¿ç”¨æœ€ä¼˜åˆ†ä½æ•°çš„æŒ‡æ ‡
            mse = quantile_metrics[best_quantile_colname]['mse']
            mae = quantile_metrics[best_quantile_colname]['mae']
            
            # print(f"  ğŸ“Š åˆ†ä½æ•°è¯„ä¼°ç»“æœ:")
            # for q, metrics in quantile_metrics.items():
            #     print(f"    {q}: MSE={metrics['mse']:.2f}, MAE={metrics['mae']:.2f}, ç»¼åˆå¾—åˆ†={metrics['combined_score']:.2f}, é¢„æµ‹æ¶¨è·Œå¹…={metrics['pred_pct']:.2f}, å®é™…æ¶¨è·Œå¹…={metrics['actual_pct']:.2f}, ç™¾åˆ†æ¯”å·®={metrics['diff_pct']:.2f}")
            print(f"  ğŸ† æœ€ä¼˜åˆ†ä½æ•°: {best_quantile_colname} (ç»¼åˆå¾—åˆ†: {best_score:.6f})")
            print(f"  ğŸ† æœ€ä¼˜åˆ†ä½æ•°(æ¶¨è·Œå¹…): {best_quantile_colname_pct} (ç™¾åˆ†æ¯”å·®: {best_diff_pct:.2f})")
            print(f"  æœ€ä¼˜(æ¶¨è·Œå¹…)é¢„æµ‹å€¼: {quantile_metrics[best_quantile_colname_pct]['pred_values']}")
            print(f"  æœ€ä¼˜(æ¶¨è·Œå¹…)å®é™…å€¼: {quantile_metrics[best_quantile_colname_pct]['actual_values']}")
            forecast_chunk["best_quantile_colname_pct"] = best_quantile_colname_pct
            forecast_chunk["best_quantile_colname"] = best_quantile_colname
            forecast_chunk["best_diff_pct"] = best_diff_pct
            forecast_chunk["best_score"] = best_score
            forecast_chunk["best_pred_pct"] = quantile_metrics[best_quantile_colname_pct]['pred_pct']
            forecast_chunk["actual_pct"] = quantile_metrics[best_quantile_colname_pct]['actual_pct']
            forecast_chunk["diff_pct"] = quantile_metrics[best_quantile_colname_pct]['diff_pct']
            forecast_chunk["mse"] = quantile_metrics[best_quantile_colname_pct]['mse']
            forecast_chunk["mae"] = quantile_metrics[best_quantile_colname_pct]['mae']
            forecast_chunk["combined_score"] = quantile_metrics[best_quantile_colname_pct]['combined_score']
            forecast_chunk["symbol"] = forecast_chunk["unique_id"]
            # try:
            #     payload = []
            #     for _, row in forecast_chunk.iterrows():
            #         item = {
            #             "symbol": row.get("symbol"),
            #             "ds": str(row.get("ds")),
            #             "tsf": float(row.get("tsf")) if row.get("tsf") is not None else 0.0,
            #             "tsf_01": float(row.get("tsf-0.1")) if row.get("tsf-0.1") is not None else 0.0,
            #             "tsf_02": float(row.get("tsf-0.2")) if row.get("tsf-0.2") is not None else 0.0,
            #             "tsf_03": float(row.get("tsf-0.3")) if row.get("tsf-0.3") is not None else 0.0,
            #             "tsf_04": float(row.get("tsf-0.4")) if row.get("tsf-0.4") is not None else 0.0,
            #             "tsf_05": float(row.get("tsf-0.5")) if row.get("tsf-0.5") is not None else 0.0,
            #             "tsf_06": float(row.get("tsf-0.6")) if row.get("tsf-0.6") is not None else 0.0,
            #             "tsf_07": float(row.get("tsf-0.7")) if row.get("tsf-0.7") is not None else 0.0,
            #             "tsf_08": float(row.get("tsf-0.8")) if row.get("tsf-0.8") is not None else 0.0,
            #             "tsf_09": float(row.get("tsf-0.9")) if row.get("tsf-0.9") is not None else 0.0,
            #             "chunk_index": chunk_index,
            #             "best_quantile": str(best_quantile_colname),
            #             "best_quantile_pct": str(best_quantile_colname_pct),
            #             "best_pred_pct": float(quantile_metrics[best_quantile_colname_pct]['pred_pct']),
            #             "actual_pct": float(quantile_metrics[best_quantile_colname_pct]['actual_pct']),
            #             "diff_pct": float(quantile_metrics[best_quantile_colname_pct]['diff_pct']),
            #             "mse": float(quantile_metrics[best_quantile_colname_pct]['mse']),
            #             "mae": float(quantile_metrics[best_quantile_colname_pct]['mae']),
            #             "combined_score": float(quantile_metrics[best_quantile_colname_pct]['combined_score']),
            #         }
            #         payload.append(item)

            #     import requests
            #     base_url = os.environ.get("GO_API_BASE_URL", "http://localhost:8080")
            #     token = os.environ.get("API_TOKEN", "fintrack-dev-token")
            #     url = f"{base_url.rstrip('/')}/api/v1/timesfm/forecast/batch"
            #     headers = {"Content-Type": "application/json", "X-Token": token}
            #     resp = requests.post(url, json=payload, headers=headers, timeout=3)
            #     if resp.status_code != 200:
            #         print(f"âš ï¸ å†™å…¥PGå¤±è´¥: HTTP {resp.status_code} {resp.text[:256]}")
            #     else:
            #         print(f"âœ… å·²å†™å…¥PGé¢„æµ‹ç»“æœ: {len(payload)} æ¡, chunk={chunk_index}")
            # except Exception as e:
            #     print(f"âš ï¸ å†™å…¥PGå¼‚å¸¸: {e}")
        # è·å–å®é™…å€¼å’Œé¢„æµ‹å€¼å¯¹åº”çš„æ—¥æœŸèŒƒå›´
        # å®é™…å€¼å’Œé¢„æµ‹å€¼å¯¹åº”çš„æ˜¯åˆ†å—ä¸­çš„æœ€åhorizon_lenä¸ªæ—¥æœŸ
        chunk_dates = df_test['ds'].tolist()
        prediction_start_date = chunk_dates[-len(actual_values)].strftime('%Y-%m-%d') if len(actual_values) > 0 else chunk['ds'].min().strftime('%Y-%m-%d')
        prediction_end_date = chunk_dates[-1].strftime('%Y-%m-%d')
        
        # ä¿æŒåŸæœ‰çš„åˆ†å—æ—¥æœŸèŒƒå›´ä½œä¸ºå¤‡ç”¨
        chunk_start_date = prediction_start_date
        chunk_end_date = prediction_end_date
        
        return ChunkPredictionResult(
            chunk_index=chunk_index,
            chunk_start_date=chunk_start_date,
            chunk_end_date=chunk_end_date,
            predictions=predictions,
            actual_values=actual_values,
            metrics={
                'mse': mse, 
                'mae': mae,
                'best_quantile_colname': best_quantile_colname,
                'best_quantile_colname_pct': best_quantile_colname_pct,
                'best_combined_score': best_score,
                'best_diff_pct': best_diff_pct,
                'all_quantile_metrics': quantile_metrics
            }
        )
        
    except Exception as e:
        print(f"åˆ†å— {chunk_index} é¢„æµ‹å¤±è´¥: {str(e)}")
        # è¿”å›ç©ºç»“æœ
        return ChunkPredictionResult(
            chunk_index=chunk_index,
            chunk_start_date="",
            chunk_end_date="",
            predictions={},
            actual_values=[],
            metrics={
                'mse': float('inf'), 
                'mae': float('inf'),
                'best_quantile_colname': 'tsf',
                'best_quantile_colname_pct': 'tsf',
                'best_combined_score': float('inf'),
                'best_diff_pct': float('inf'),
                'all_quantile_metrics': {}
            }
        )

async def predict_chunked_mode_for_best(request: ChunkedPredictionRequest, tfm = None, timesfm_version = "2.0") -> ChunkedPredictionResponse:
    """
    æ¨¡å¼1åˆ†å—é¢„æµ‹ä¸»å‡½æ•° - æ”¯æŒåˆ†å—é¢„æµ‹ã€æœ€ä½³åˆ†æ•°é€‰æ‹©å’Œåœ¨éªŒè¯é›†ä¸ŠéªŒè¯
    
    Args:
        request: åˆ†å—é¢„æµ‹è¯·æ±‚
        tfm: TimesFMæ¨¡å‹å®ä¾‹
        
    Returns:
        ChunkedPredictionResponse: åˆ†å—é¢„æµ‹å“åº”ï¼ŒåŒ…å«æœ€ä½³é¢„æµ‹é¡¹å’ŒéªŒè¯ç»“æœ
    """
    import time
    start_time = time.time()
    
    try:
        # æ•°æ®é¢„å¤„ç†
        df_original, df_train, df_test, df_val = await df_preprocess(
            request.stock_code, 
            request.stock_type, 
            request.start_date,
            request.end_date,
            request.time_step, 
            years=request.years, 
            horizon_len=request.horizon_len
        )
        
        # æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æˆåŠŸ
        if df_original is None or df_train is None or df_test is None or df_val is None:
            print(f"âŒ è‚¡ç¥¨ {request.stock_code} æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            return ChunkedPredictionResponse(
                stock_code=request.stock_code,
                total_chunks=0,
                horizon_len=request.horizon_len,
                chunk_results=[],
                overall_metrics={
                    'avg_mse': float('inf'),
                    'avg_mae': float('inf'),
                    'error': 'Data preprocessing failed'
                },
                processing_time=time.time() - start_time
            )
        
        print(f"âœ… è‚¡ç¥¨ {request.stock_code} æ•°æ®é¢„å¤„ç†æˆåŠŸ")
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: è®­ç»ƒé›†={len(df_train)}, æµ‹è¯•é›†={len(df_test)}, éªŒè¯é›†={len(df_val)}")
        
        # æ·»åŠ å”¯ä¸€æ ‡è¯†ç¬¦
        df_train["unique_id"] = df_train["stock_code"].astype(str)
        df_test["unique_id"] = df_test["stock_code"].astype(str)
        df_val["unique_id"] = df_val["stock_code"].astype(str)
        
        # å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†å—ï¼ˆè‡ªåŠ¨è®¡ç®—åˆ†å—æ•°é‡ï¼Œä¸ä½¿ç”¨chunk_numé™åˆ¶ï¼‰
        chunks = create_chunks_from_test_data(df_test, request.horizon_len)
        active_chunks = chunks
        
        # å¯¹æ¯ä¸ªåˆ†å—è¿›è¡Œé¢„æµ‹
        chunk_results = []
        all_mse = []
        all_mae = []
        all_predictions = []  # å­˜å‚¨æ‰€æœ‰åˆ†å—çš„æ‰€æœ‰é¢„æµ‹ç»“æœ
                
        for i, chunk in enumerate(active_chunks):
            print(f"æ­£åœ¨å¤„ç†æµ‹è¯•é›†åˆ†å— {i+1}/{len(active_chunks)}...")
            history_len = i * request.horizon_len
            if history_len > 0:
                df_train_current = pd.concat([df_train, df_test.iloc[:history_len, :]], axis=0)
            else:
                df_train_current = df_train
                
            result = predict_single_chunk_mode1(
                df_train=df_train_current,
                df_test=chunk,
                tfm=tfm,
                chunk_index=i,
                timesfm_version=timesfm_version,
                symbol=request.stock_code,
            )
            
            chunk_results.append(result)
            
            # æ”¶é›†æŒ‡æ ‡ç”¨äºè®¡ç®—æ€»ä½“æŒ‡æ ‡
            if result.metrics['mse'] != float('inf'):
                all_mse.append(result.metrics['mse'])
                all_mae.append(result.metrics['mae'])
                
            # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ
            if result.predictions:
                all_predictions.append({
                    'chunk_index': i,
                    'predictions': result.predictions,
                    'actual_values': result.actual_values,
                    'dates': pd.date_range(
                        start=pd.to_datetime(result.chunk_start_date),
                        end=pd.to_datetime(result.chunk_end_date),
                        freq='D'
                    )[:len(result.actual_values)]
                })
        
        # åˆ†ææœ€ä½³é¢„æµ‹é¡¹ (tsf-0.1 åˆ° tsf-0.9)
        best_prediction_item = None
        best_score = float('inf')
        best_metrics = {}
        
        prediction_items = [f"tsf-0.{i}" for i in range(1, 10)]
        
        for item in prediction_items:
            item_mse = []
            item_mae = []
            item_returns = []  # æ¶¨è·Œå¹…
            
            for pred_data in all_predictions:
                if item in pred_data['predictions']:
                    pred_values = pred_data['predictions'][item]
                    actual_values = pred_data['actual_values']
                    
                    # è®¡ç®—MSEå’ŒMAE
                    mse = mean_squared_error(actual_values, pred_values)
                    mae = mean_absolute_error(actual_values, pred_values)
                    item_mse.append(mse)
                    item_mae.append(mae)
                    
                    # è®¡ç®—æ¶¨è·Œå¹…
                    if len(pred_values) >= 2 and len(actual_values) >= 2:
                        pred_return = (pred_values[-1] - pred_values[0]) / pred_values[0] * 100
                        actual_return = (actual_values[-1] - actual_values[0]) / actual_values[0] * 100
                        item_returns.append(abs(pred_return - actual_return))
            
            if item_mse:
                avg_mse = np.mean(item_mse)
                avg_mae = np.mean(item_mae)
                avg_return_diff = np.mean(item_returns) if item_returns else float('inf')
                
                # ç»¼åˆè¯„åˆ† (MSEæƒé‡0.3, MAEæƒé‡0.3, æ¶¨è·Œå¹…å·®å¼‚æƒé‡0.4)
                composite_score = 0.3 * avg_mse + 0.3 * avg_mae + 0.4 * avg_return_diff
                
                if composite_score < best_score:
                    best_score = composite_score
                    best_prediction_item = item
                    best_metrics = {
                        'mse': avg_mse,
                        'mae': avg_mae,
                        'return_diff': avg_return_diff,
                        'composite_score': composite_score
                    }
        
        print(f"ğŸ¯ æœ€ä½³é¢„æµ‹é¡¹: {best_prediction_item}")
        print(f"ğŸ“Š æœ€ä½³æŒ‡æ ‡: MSE={best_metrics.get('mse', 'N/A'):.4f}, "
                f"MAE={best_metrics.get('mae', 'N/A'):.4f}, "
                f"æ¶¨è·Œå¹…å·®å¼‚={best_metrics.get('return_diff', 'N/A'):.2f}%")
        
        # åœ¨éªŒè¯é›†ä¸Šä½¿ç”¨æœ€ä½³é¢„æµ‹é¡¹è¿›è¡ŒéªŒè¯
        validation_results = None
        if best_prediction_item and len(df_val) >= request.horizon_len:
            print(f"ğŸ” ä½¿ç”¨æœ€ä½³é¢„æµ‹é¡¹ {best_prediction_item} åœ¨éªŒè¯é›†ä¸Šè¿›è¡ŒéªŒè¯...")
            
            # å¯¹éªŒè¯é›†è¿›è¡Œåˆ†å—
            val_chunks = create_chunks_from_test_data(df_val, request.horizon_len)
            val_results = []
            
            for i, val_chunk in enumerate(val_chunks):
                # ä½¿ç”¨ä¸æµ‹è¯•é›†ç›¸åŒçš„å¤„ç†æ–¹å¼ï¼šéšç€åˆ†å—æ•°æ®å¹³ç§»
                print(f"æ­£åœ¨å¤„ç†éªŒè¯é›†åˆ†å— {i+1}/{len(val_chunks)}...")
                history_len = i * request.horizon_len
                if history_len > 0:
                    # ä½¿ç”¨è®­ç»ƒé›†+æµ‹è¯•é›†+éªŒè¯é›†çš„å‰history_lenè¡Œæ•°æ®
                    cumulative_train_data = pd.concat([df_train, df_test, df_val.iloc[:history_len, :]], axis=0)
                else:
                    # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œåªä½¿ç”¨è®­ç»ƒé›†+æµ‹è¯•é›†
                    cumulative_train_data = pd.concat([df_train, df_test], axis=0)
                
                val_result = predict_single_chunk_mode1(
                    df_train=cumulative_train_data,  # ä½¿ç”¨è®­ç»ƒé›†+æµ‹è¯•é›†+ä¹‹å‰éªŒè¯åˆ†å—
                    df_test=val_chunk,
                    tfm=tfm,
                    chunk_index=i,
                    timesfm_version=timesfm_version,
                    symbol=request.stock_code,
                )
                val_results.append(val_result)
            
            # è®¡ç®—éªŒè¯é›†æŒ‡æ ‡
            val_mse = []
            val_mae = []
            val_returns = []
            
            for result in val_results:
                if best_prediction_item in result.predictions:
                    pred_values = result.predictions[best_prediction_item]
                    actual_values = result.actual_values
                    
                    mse = mean_squared_error(actual_values, pred_values)
                    mae = mean_absolute_error(actual_values, pred_values)
                    val_mse.append(mse)
                    val_mae.append(mae)
                    
                    if len(pred_values) >= 2 and len(actual_values) >= 2:
                        pred_return = (pred_values[-1] - pred_values[0]) / pred_values[0] * 100
                        actual_return = (actual_values[-1] - actual_values[0]) / actual_values[0] * 100
                        val_returns.append(abs(pred_return - actual_return))
            
            validation_results = {
                'best_prediction_item': best_prediction_item,
                'validation_mse': np.mean(val_mse) if val_mse else float('inf'),
                'validation_mae': np.mean(val_mae) if val_mae else float('inf'),
                'validation_return_diff': np.mean(val_returns) if val_returns else float('inf'),
                'validation_chunks': len(val_results),
                'successful_validation_chunks': len(val_mse)
            }
            
            print(f"âœ… éªŒè¯ç»“æœ: MSE={validation_results['validation_mse']:.4f}, "
                  f"MAE={validation_results['validation_mae']:.4f}, "
                  f"æ¶¨è·Œå¹…å·®å¼‚={validation_results['validation_return_diff']:.2f}%")
        
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        overall_metrics = {
            'avg_mse': np.mean(all_mse) if all_mse else float('inf'),
            'avg_mae': np.mean(all_mae) if all_mae else float('inf'),
            'total_chunks': len(chunks),
            'successful_chunks': len(all_mse),
            'best_prediction_item': best_prediction_item,
            'best_metrics': best_metrics,
            'validation_results': validation_results
        }
        
        # æ‹¼æ¥æ‰€æœ‰åˆ†å—çš„é¢„æµ‹ç»“æœ
        concatenated_predictions = {}
        concatenated_actual = []
        concatenated_dates = []
        
        if chunk_results:
            # è·å–é¢„æµ‹åˆ—åï¼ˆä»ç¬¬ä¸€ä¸ªåˆ†å—ç»“æœä¸­è·å–ï¼‰
            prediction_columns = list(chunk_results[0].predictions.keys())
            
            # åˆå§‹åŒ–æ‹¼æ¥é¢„æµ‹ç»“æœå­—å…¸
            for col in prediction_columns:
                concatenated_predictions[col] = []
            
            # æ‹¼æ¥æ¯ä¸ªåˆ†å—çš„ç»“æœ
            for result in chunk_results:
                start_date = pd.to_datetime(result.chunk_start_date, errors='coerce')
                end_date = pd.to_datetime(result.chunk_end_date, errors='coerce')
                chunk_size = len(result.actual_values)
                if chunk_size == 0 or pd.isna(start_date) or pd.isna(end_date):
                    continue

                for col in prediction_columns:
                    if col in result.predictions:
                        concatenated_predictions[col].extend(result.predictions[col])
                    else:
                        concatenated_predictions[col].extend([float('nan')] * chunk_size)

                concatenated_actual.extend(result.actual_values)

                chunk_dates = pd.date_range(start=start_date, end=end_date, freq='D')
                concatenated_dates.extend([date.strftime('%Y-%m-%d') for date in chunk_dates[:chunk_size]])
        
        processing_time = time.time() - start_time
        
        return ChunkedPredictionResponse(
            stock_code=request.stock_code,
            total_chunks=len(chunks),
            horizon_len=request.horizon_len,
            chunk_results=chunk_results,
            overall_metrics=overall_metrics,
            processing_time=processing_time,
            concatenated_predictions=concatenated_predictions if concatenated_predictions else None,
            concatenated_actual=concatenated_actual if concatenated_actual else None,
            concatenated_dates=concatenated_dates if concatenated_dates else None
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"åˆ†å—é¢„æµ‹å¤±è´¥: {str(e)} é”™è¯¯è¡Œ {e.__traceback__.tb_lineno}")
        
        return ChunkedPredictionResponse(
            stock_code=request.stock_code,
            total_chunks=0,
            horizon_len=request.horizon_len,
            chunk_results=[],
            overall_metrics={'avg_mse': float('inf'), 'avg_mae': float('inf'), 'error': str(e)},
            processing_time=processing_time
        )

if __name__ == "__main__":
    import asyncio
    from timesfm_init import init_timesfm
    test_request = ChunkedPredictionRequest(
        stock_code="sh600398",
        years=10,
        horizon_len=7,
        start_date="20100101",
        end_date="20251114",
        context_len=2048,
        time_step=0,
        stock_type=1,
        chunk_num=5,
        timesfm_version="2.5",
    )
    if test_request.timesfm_version == "2.0":
        tfm = init_timesfm(horizon_len=test_request.horizon_len, context_len=test_request.context_len)
        response = asyncio.run(predict_chunked_mode_for_best(test_request, tfm, timesfm_version=test_request.timesfm_version))
    else:
        response = asyncio.run(predict_chunked_mode_for_best(test_request, tfm=None, timesfm_version=test_request.timesfm_version))
    # print(response)
    # è¾“å‡ºç»“æœ
    print(f"\n=== åˆ†å—é¢„æµ‹ç»“æœ ===")
    print(f"è‚¡ç¥¨ä»£ç : {response.stock_code}")
    print(f"æ€»åˆ†å—æ•°: {response.total_chunks}")
    print(f"é¢„æµ‹é•¿åº¦: {response.horizon_len}")
    print(f"å¤„ç†æ—¶é—´: {response.processing_time:.2f} ç§’")
    print(f"å¤„ç†ç»“æœ: {response.overall_metrics}")
    # ç”Ÿæˆç»˜å›¾
    from plot_functions import plot_chunked_prediction_results
    print(f"\næ­£åœ¨ç”Ÿæˆç»“æœå›¾è¡¨...")
    plot_save_path = os.path.join(finance_dir, f"forecast-results/{test_request.stock_code}_prediction_plot.png")
    try:
        plot_path = plot_chunked_prediction_results(response, plot_save_path)
        print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_path}")
    except Exception as plot_error:
        print(f"âš ï¸ ç»˜å›¾å¤±è´¥: {str(plot_error)}")
    
    
